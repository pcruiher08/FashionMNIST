{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 10:47:50.801818: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-06 10:47:50.802006: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Add, Multiply\n",
    "from keras.layers import ELU, PReLU, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adagrad\n",
    "from keras import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import math as m\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "edgecolors=None\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "\n",
    "class AutomaticLearning:\n",
    "\n",
    "\n",
    "\n",
    "  def __init__(self , train_images, train_labels, test_images, test_labels, title, model_name):\n",
    "\n",
    "    #print(dataframe.head(2))\n",
    "\n",
    "    #self.df = dataframe\n",
    "    self.train_images = train_images\n",
    "    self.train_labels = train_labels\n",
    "    self.test_images = test_images\n",
    "    self.test_labels = test_labels\n",
    "\n",
    "    self.model_name = model_name\n",
    "    self.input_shape = None\n",
    "    self.num_classes = None\n",
    "    self.epochs = None\n",
    "    self.model = None\n",
    "    self.X = None\n",
    "    self.y = None\n",
    "    self.X_train = None\n",
    "    self.X_test = None\n",
    "    self.y_train = None\n",
    "    self.y_test = None\n",
    "    self.run_name = \"run\"\n",
    "    self.history = None\n",
    "    self.r2 = None\n",
    "    self.loss = None\n",
    "    self.mse = None\n",
    "    self.mae = None\n",
    "    self.rmse = None\n",
    "    self.library = None\n",
    "    self.title = title\n",
    "    self.plottittle = \"\"\n",
    "    self.save = None\n",
    "    self.show = None\n",
    "    self.y_pred = None\n",
    "    return\n",
    "\n",
    "  def gather_data(self):\n",
    "    return {'r2': self.r2, 'loss': self.loss, 'mse': self.mse, 'mae': self.mae, 'rmse': self.rmse}\n",
    "\n",
    "  def plotA(self):\n",
    "    pd.DataFrame(self.history.history).plot(figsize=(8,5))\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "  def plotLinear(self):\n",
    "    # plot the data and the predictions\n",
    "\n",
    "    #print(self.X_test)\n",
    "    predictions = self.model.predict(self.X_test)\n",
    "\n",
    "    plt.xlabel('Area (pixels^2)')\n",
    "    plt.ylabel('Mass (g)')\n",
    "\n",
    "    plt.scatter(self.X_test, self.y_test)\n",
    "    if(self.model_name == \"SVR\"):\n",
    "      plt.scatter(self.X_test, predictions, color='red', marker=\"x\")\n",
    "    else:\n",
    "      plt.plot(self.X_test, predictions, color='red')\n",
    "\n",
    "    plt.title(self.plottittle +'-R2' + str(self.epochs), size = 20)\n",
    "\n",
    "    if(self.show):\n",
    "      plt.show()\n",
    "      print()\n",
    "    if(self.save):\n",
    "      plt.savefig(self.folder +'/'+self.plottittle + '-R2' + str(self.epochs), dpi=200)\n",
    "    #print(f'R-squared value: {self.r2:.4f}')\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    plt.scatter(self.y_test, predictions)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.text(0.05, 0.95, 'R^2 = {:.4f}'.format(self.r2), ha='left', va='center', transform=plt.gca().transAxes)\n",
    "    plt.title(self.plottittle + '-Predictions', size = 20)\n",
    "    if(self.show):\n",
    "      print()\n",
    "      plt.show()\n",
    "    if(self.save):\n",
    "      plt.savefig(self.folder +'/'+self.plottittle + '-Predictions'+ str(self.epochs), dpi=200)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "  def plotLoss(self):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set(title='Loss')\n",
    "    ax.plot(self.history.history['loss'], label='Loss')\n",
    "    ax.plot(self.history.history['val_loss'], label='Val loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "  def plotMSE(self):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set(title='MSE')\n",
    "    ax.plot(self.history.history['mse'], label='MSE')\n",
    "    ax.plot(self.history.history['val_mse'], label='Val MSE')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return\n",
    "    \n",
    "\n",
    "  def plotMAE(self):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set(title='MAE')\n",
    "    ax.plot(self.history.history['mae'], label='MAE')\n",
    "    ax.plot(self.history.history['val_mae'], label='Val MAE')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "  def plotRMSE(self):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set(title='RMSE')\n",
    "    ax.plot(self.history.history['root_mean_squared_error'], label='RMSE')\n",
    "    ax.plot(self.history.history['val_root_mean_squared_error'], label='Val RMSE')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return\n",
    "  \n",
    "  def printAccuracy(self):\n",
    "\n",
    "    accuracy = self.model.evaluate(self.test_images, self.test_labels)\n",
    "    print('Test Accuracy:', accuracy)\n",
    "\n",
    "  def plotAccuracy(self):\n",
    "    plt.plot(self.history.history['accuracy'])  # Use 'acc' instead of 'accuracy'\n",
    "    plt.plot(self.history.history['val_accuracy'])  # Use 'val_acc' instead of 'val_accuracy'\n",
    "    #plt.title('Training and Validation Accuracy')\n",
    "    plt.title(self.plottittle + '-Training and Validation Accuracy', size = 20)\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    if(self.save):\n",
    "      plt.savefig(self.folder +'/'+self.plottittle + '-Accuracy'+ str(self.epochs), dpi=300)\n",
    "    plt.clf()\n",
    "\n",
    "    #plt.show()\n",
    "\n",
    "  def plotROC(self):\n",
    "    # Step 1: Make predictions\n",
    "\n",
    "\n",
    "    # Step 2: Compute prediction probabilities for the positive class\n",
    "    y_pred_positive = self.y_pred[:, 1]\n",
    "\n",
    "    # Step 3: Compute ROC curve metrics\n",
    "    fpr, tpr, thresholds = roc_curve(self.y_train, y_pred_positive)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Step 4: Plot the ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Random guessing line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    #plt.show()\n",
    "\n",
    "  def plotClas(self):\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    #predictions = model.predict(x_test)\n",
    "    self.y_pred = self.model.predict(self.test_images)\n",
    "\n",
    "    predicted_labels = np.argmax(self.y_pred, axis=1)\n",
    "\n",
    "    # Plot a grid of images with their predicted labels\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "\n",
    "    plt.figure(figsize=(12, 14))\n",
    "    plt.title(self.plottittle + '-Classification', size = 20)\n",
    "\n",
    "    for i in range(25):\n",
    "        \n",
    "\n",
    "      plt.subplot(5, 5, i + 1)\n",
    "      plt.xticks([])\n",
    "      plt.yticks([])\n",
    "      plt.grid(False)\n",
    "\n",
    "\n",
    "\n",
    "      image = (self.test_images[i] - np.min(self.test_images[i])) / (np.max(self.test_images[i]) - np.min(self.test_images[i]))\n",
    "      plt.imshow(image, cmap=plt.cm.gray)  # Change the color map if needed\n",
    "      predicted_label = predicted_labels[i]\n",
    "      true_label = self.test_labels[i]\n",
    "\n",
    " \n",
    "      if predicted_label == true_label:\n",
    "          color = 'green'\n",
    "      else:\n",
    "          color = 'red'\n",
    "\n",
    "      plt.xlabel(f\"Predicted: {class_names[predicted_label]}\\nTrue: {class_names[true_label]}\", color=color)\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "    if(self.save):\n",
    "      plt.savefig(self.folder +'/'+self.plottittle + '-Classification'+ str(self.epochs), dpi=300)\n",
    "\n",
    "\n",
    "    if(self.show):\n",
    "      #plt.show()\n",
    "      print()\n",
    "    plt.clf()\n",
    "  \n",
    "  def plotPredictions(self):\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "\n",
    "    self.y_pred = self.model.predict(self.test_images)\n",
    "    y_pred_classes = np.argmax(self.y_pred, axis=1)\n",
    "\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(self.test_labels, y_pred_classes)\n",
    "\n",
    "\n",
    "    #print(f'R-squared value: {self.r2:.4f}')\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "\n",
    "    plt.title(self.plottittle + '-Confusion Matrix', size = 20)\n",
    "\n",
    "    if(self.save):\n",
    "      plt.savefig(self.folder +'/'+self.plottittle + '-Confusion Matrix'+ str(self.epochs), dpi=300)\n",
    "\n",
    "\n",
    "    if(self.show):\n",
    "      #plt.show()\n",
    "      print()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "  def plotAll(self):\n",
    "\n",
    "    fig, ax = plt.subplots(nrows = 2, ncols = 2, figsize = (15,15))\n",
    "   \n",
    "    fig.suptitle(self.plottittle, size = 35)   \n",
    "\n",
    "    ax[0][0].set(title='Loss')\n",
    "    ax[0][0].plot(self.history.history['loss'], label='Loss')\n",
    "    ax[0][0].plot(self.history.history['val_loss'], label='Val loss')\n",
    "    ax[0][0].set_xlabel('Epoch')\n",
    "    ax[0][0].set_ylabel('Values')\n",
    "    ax[0][0].legend()\n",
    "\n",
    "\n",
    "    ax[0][1].set(title='MSE')\n",
    "    ax[0][1].plot(self.history.history['mse'], label='MSE')\n",
    "    ax[0][1].plot(self.history.history['val_mse'], label='Val MSE')\n",
    "    ax[0][1].set_xlabel('Epoch')\n",
    "    ax[0][1].set_ylabel('Values')\n",
    "    ax[0][1].legend()\n",
    "\n",
    "   \n",
    "\n",
    "    ax[1][0].set(title='MAE')\n",
    "    ax[1][0].plot(self.history.history['mae'], label='MAE')\n",
    "    ax[1][0].plot(self.history.history['val_mae'], label='Val MAE')\n",
    "    ax[1][0].set_xlabel('Epoch')\n",
    "    ax[1][0].set_ylabel('Values')\n",
    "    ax[1][0].legend()\n",
    "\n",
    "    ax[1][1].set(title='RMSE')\n",
    "    ax[1][1].plot(self.history.history['root_mean_squared_error'], label='RMSE')\n",
    "    ax[1][1].plot(self.history.history['val_root_mean_squared_error'], label='Val RMSE')\n",
    "    ax[1][1].set_xlabel('Epoch')\n",
    "    ax[1][1].set_ylabel('Values')\n",
    "    ax[1][1].legend()\n",
    "\n",
    "    if(self.save):\n",
    "      #print(\"IM SAVING\", self.save)\n",
    "\n",
    "      plt.savefig(self.folder +'/'+self.plottittle+'-Summary'+ str(self.epochs), dpi=200)\n",
    "\n",
    "    if(self.show):\n",
    "      #print(\"IM SHOWING\", self.show)\n",
    "\n",
    "      plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "  def plotNonLinear(self):\n",
    "    print(self.history.history.keys())\n",
    "\n",
    "    self.plotAll()\n",
    "    self.plotPredictions()\n",
    "    self.printAccuracy()\n",
    "    self.plotAccuracy()\n",
    "    self.plotClas()\n",
    "    #self.plotROC()\n",
    "    #self.plotLoss()\n",
    "    #self.plotMAE()\n",
    "    #self.plotMSE()\n",
    "    #self.plotRMSE()\n",
    "    return\n",
    "\n",
    "  def plot(self, folder, save, show):\n",
    "    self.save = save\n",
    "    self.show = show\n",
    "    self.folder = folder\n",
    "    if not os.path.exists(self.folder):\n",
    "      #print(\"creating folder:\", self.folder)\n",
    "      os.makedirs(self.folder)\n",
    "\n",
    "    if(self.library == \"Tensorflow\"):\n",
    "      if(self.save and self.show): \n",
    "        print(self.model.summary())\n",
    "        #plot_model(self.folder + '/' + self.model, to_file= self.model_name + \"-\" + self.run_name + \"-\" + self.title + '.png', show_shapes=True, show_layer_names=False)\n",
    "        #plot_model(self.model, show_shapes=True, show_layer_names=False)\n",
    "      if(self.save):\n",
    "        print(\"IM SAVING\")\n",
    "        #img = mpimg.imread(self.title +'/'+ self.model_name + \"-\" + self.run_name + \"-\" + self.title + '.png')\n",
    "      if(self.show):\n",
    "        print(\"IM SHOWING\")\n",
    "        #imgplot = plt.imshow(img)\n",
    "        #imgplot = plt.imshow(img2)\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "    if(self.library == \"Tensorflow\"):\n",
    "      self.plotNonLinear()\n",
    "    elif(self.library == \"scikit\"):\n",
    "      #print(\"plotting linear\")\n",
    "      self.plotLinear()\n",
    "\n",
    "\n",
    "  def train(self, epochs = 2):\n",
    "\n",
    "    self.epochs = epochs\n",
    "    self.plottittle = self.title\n",
    "\n",
    "    if(self.library == \"Tensorflow\"):\n",
    "      opt = optimizers.Adam(learning_rate=0.01)\n",
    "      sgd = optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "      \n",
    "      self.model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer = opt, metrics=['mse', 'mae','accuracy', tf.keras.metrics.RootMeanSquaredError()])      \n",
    "      early_stop = EarlyStopping(monitor='val_loss', patience=250, verbose=1)\n",
    "\n",
    "      self.history = self.model.fit(self.X_train, self.y_train, batch_size=32, epochs = self.epochs, validation_split=0.2, shuffle = True,callbacks=[early_stop], verbose = 1)\n",
    "      K.clear_session()\n",
    "      #['loss', 'mse', 'mae', 'root_mean_squared_error']\n",
    "      results = self.model.evaluate(self.X_test, self.y_test)\n",
    "      self.loss = results[0]\n",
    "      self.mse = results[1]\n",
    "      self.mae = results[2]\n",
    "      self.rmse = results[3]\n",
    "   \n",
    "    return\n",
    "  \n",
    "  def buildData(self):\n",
    "\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    if(self.model_name == 'CNN' or self.model_name == 'CNN2' or self.model_name == 'ResNet' or self.model_name == 'MobileNet' or self.model_name == 'DenseNet'):\n",
    "\n",
    "      \n",
    "      self.train_images = np.expand_dims(self.train_images, axis=-1)\n",
    "      self.train_images = np.repeat(self.train_images, 3, axis=-1)\n",
    "      self.train_images = keras.applications.mobilenet.preprocess_input(self.train_images)\n",
    "      self.train_images = tf.image.resize(self.train_images, (32, 32))\n",
    "      self.test_images = np.expand_dims(self.test_images, axis=-1)\n",
    "      self.test_images = np.repeat(self.test_images, 3, axis=-1)\n",
    "      self.test_images = keras.applications.mobilenet.preprocess_input(self.test_images)\n",
    "      self.test_images = tf.image.resize(self.test_images, (32, 32))\n",
    "\n",
    "\n",
    "      self.train_images = self.train_images / 255.0\n",
    "      self.test_images = self.test_images / 255.0\n",
    "      print()\n",
    "        \n",
    "\n",
    "    self.X_train = self.train_images\n",
    "    self.X_test = self.test_images\n",
    "\n",
    "    self.y_train = self.train_labels\n",
    "    self.y_test = self.test_labels\n",
    "\n",
    "    self.input_shape = (32, 32, 3)\n",
    "    num_classes = 1\n",
    "    return\n",
    "\n",
    "\n",
    "  def buildModel(self):\n",
    "    if(self.model_name == \"CNN2\"):\n",
    "      print(\"training cnn2\")\n",
    "      self.library = \"Tensorflow\"\n",
    "\n",
    "      self.model = keras.Sequential([\n",
    "          keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "          keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "          keras.layers.BatchNormalization(),\n",
    "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "          keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "          keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "          keras.layers.BatchNormalization(),\n",
    "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "          keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "          keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "          keras.layers.BatchNormalization(),\n",
    "          keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'),\n",
    "          keras.layers.Flatten(),\n",
    "          keras.layers.Dense(512, activation='relu'),\n",
    "          keras.layers.Dropout(0.5),\n",
    "          keras.layers.Dense(256, activation='relu'),\n",
    "          keras.layers.Dropout(0.5),\n",
    "          keras.layers.Dense(10, activation='softmax')\n",
    "      ])\n",
    "    elif(self.model_name == \"CNN\"):\n",
    "      print(\"training cnnn\")\n",
    "      self.library = \"Tensorflow\"\n",
    "      self.model = keras.Sequential([\n",
    "          keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "          keras.layers.MaxPooling2D((2, 2)),\n",
    "          keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "          keras.layers.MaxPooling2D((2, 2)),\n",
    "          keras.layers.Flatten(),\n",
    "          keras.layers.Dense(64, activation='relu'),\n",
    "          keras.layers.Dense(10, activation='softmax')\n",
    "      ])\n",
    "    elif(self.model_name == \"ResNet\"):\n",
    "      self.library = \"Tensorflow\"\n",
    "      base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "      x = base_model.output\n",
    "      x = GlobalAveragePooling2D()(x)\n",
    "      x = Dense(1, activation='linear')(x)\n",
    "      predictions = Dense(10, activation='softmax')(x)\n",
    "      self.model = Model(inputs=base_model.input, outputs=predictions)\n",
    "      for layer in base_model.layers:\n",
    "          layer.trainable = False\n",
    "\n",
    "\n",
    "    elif(self.model_name == \"DenseNet\"):\n",
    "      self.library = \"Tensorflow\"\n",
    "\n",
    "      base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "      x = base_model.output\n",
    "      x = GlobalAveragePooling2D()(x)\n",
    "      x = Dense(1, activation='linear')(x)\n",
    "      predictions = Dense(10, activation='softmax')(x)\n",
    "      self.model = Model(inputs=base_model.input, outputs=predictions)\n",
    "      for layer in base_model.layers:\n",
    "          layer.trainable = False\n",
    "\n",
    "    elif(self.model_name == \"MobileNet\"):\n",
    "      self.library = \"Tensorflow\"\n",
    "\n",
    "      base_model = MobileNet(weights='imagenet',include_top=False, input_shape=(32, 32, 3))\n",
    "      x = base_model.output\n",
    "      x = GlobalAveragePooling2D()(x)\n",
    "      x = Dense(1, activation='linear')(x)\n",
    "      predictions = Dense(10, activation='softmax')(x)\n",
    "      self.model = Model(inputs=base_model.input, outputs=predictions)\n",
    "      for layer in base_model.layers:\n",
    "          layer.trainable = False\n",
    "    return\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs using ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training cnnn\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablo/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2023-06-06 10:51:42.381034: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.6992 - mse: 27.7352 - mae: 4.4293 - accuracy: 0.7341 - root_mean_squared_error: 5.2664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 10:52:01.965169: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 23s 14ms/step - loss: 0.6991 - mse: 27.7358 - mae: 4.4294 - accuracy: 0.7341 - root_mean_squared_error: 5.2665 - val_loss: 0.5280 - val_mse: 27.3835 - val_mae: 4.3824 - val_accuracy: 0.8033 - val_root_mean_squared_error: 5.2329\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 20s 13ms/step - loss: 0.5120 - mse: 27.7449 - mae: 4.4294 - accuracy: 0.8093 - root_mean_squared_error: 5.2673 - val_loss: 0.4983 - val_mse: 27.3854 - val_mae: 4.3824 - val_accuracy: 0.8198 - val_root_mean_squared_error: 5.2331\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.4682 - mse: 27.7471 - mae: 4.4294 - accuracy: 0.8242 - root_mean_squared_error: 5.2676 - val_loss: 0.5209 - val_mse: 27.3962 - val_mae: 4.3824 - val_accuracy: 0.8162 - val_root_mean_squared_error: 5.2341\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.4419 - mse: 27.7485 - mae: 4.4294 - accuracy: 0.8376 - root_mean_squared_error: 5.2677 - val_loss: 0.4535 - val_mse: 27.3928 - val_mae: 4.3824 - val_accuracy: 0.8323 - val_root_mean_squared_error: 5.2338\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.4229 - mse: 27.7495 - mae: 4.4294 - accuracy: 0.8434 - root_mean_squared_error: 5.2678 - val_loss: 0.4278 - val_mse: 27.3938 - val_mae: 4.3824 - val_accuracy: 0.8440 - val_root_mean_squared_error: 5.2339\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.4162 - mse: 27.7499 - mae: 4.4294 - accuracy: 0.8453 - root_mean_squared_error: 5.2678 - val_loss: 0.4199 - val_mse: 27.3934 - val_mae: 4.3824 - val_accuracy: 0.8424 - val_root_mean_squared_error: 5.2339\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 0.4066 - mse: 27.7504 - mae: 4.4294 - accuracy: 0.8501 - root_mean_squared_error: 5.2679 - val_loss: 0.4117 - val_mse: 27.3924 - val_mae: 4.3824 - val_accuracy: 0.8488 - val_root_mean_squared_error: 5.2338\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 20s 13ms/step - loss: 0.4012 - mse: 27.7508 - mae: 4.4294 - accuracy: 0.8525 - root_mean_squared_error: 5.2679 - val_loss: 0.4216 - val_mse: 27.3965 - val_mae: 4.3824 - val_accuracy: 0.8472 - val_root_mean_squared_error: 5.2342\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.3946 - mse: 27.7510 - mae: 4.4294 - accuracy: 0.8522 - root_mean_squared_error: 5.2679 - val_loss: 0.3946 - val_mse: 27.3942 - val_mae: 4.3824 - val_accuracy: 0.8554 - val_root_mean_squared_error: 5.2340\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.3905 - mse: 27.7513 - mae: 4.4294 - accuracy: 0.8531 - root_mean_squared_error: 5.2679 - val_loss: 0.4293 - val_mse: 27.3957 - val_mae: 4.3824 - val_accuracy: 0.8372 - val_root_mean_squared_error: 5.2341\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 20s 13ms/step - loss: 0.3887 - mse: 27.7515 - mae: 4.4294 - accuracy: 0.8560 - root_mean_squared_error: 5.2680 - val_loss: 0.4016 - val_mse: 27.3960 - val_mae: 4.3824 - val_accuracy: 0.8544 - val_root_mean_squared_error: 5.2341\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 20s 13ms/step - loss: 0.3835 - mse: 27.7516 - mae: 4.4294 - accuracy: 0.8569 - root_mean_squared_error: 5.2680 - val_loss: 0.3970 - val_mse: 27.3931 - val_mae: 4.3824 - val_accuracy: 0.8529 - val_root_mean_squared_error: 5.2338\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.3816 - mse: 27.7518 - mae: 4.4294 - accuracy: 0.8581 - root_mean_squared_error: 5.2680 - val_loss: 0.3927 - val_mse: 27.3964 - val_mae: 4.3824 - val_accuracy: 0.8553 - val_root_mean_squared_error: 5.2342\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 20s 13ms/step - loss: 0.3818 - mse: 27.7518 - mae: 4.4294 - accuracy: 0.8573 - root_mean_squared_error: 5.2680 - val_loss: 0.4090 - val_mse: 27.3922 - val_mae: 4.3824 - val_accuracy: 0.8518 - val_root_mean_squared_error: 5.2338\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.3768 - mse: 27.7521 - mae: 4.4294 - accuracy: 0.8595 - root_mean_squared_error: 5.2680 - val_loss: 0.3849 - val_mse: 27.3954 - val_mae: 4.3824 - val_accuracy: 0.8580 - val_root_mean_squared_error: 5.2341\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 20s 13ms/step - loss: 0.3763 - mse: 27.7521 - mae: 4.4294 - accuracy: 0.8582 - root_mean_squared_error: 5.2680 - val_loss: 0.3927 - val_mse: 27.3939 - val_mae: 4.3824 - val_accuracy: 0.8481 - val_root_mean_squared_error: 5.2339\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.3731 - mse: 27.7521 - mae: 4.4294 - accuracy: 0.8594 - root_mean_squared_error: 5.2680 - val_loss: 0.4115 - val_mse: 27.3930 - val_mae: 4.3824 - val_accuracy: 0.8435 - val_root_mean_squared_error: 5.2338\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 19s 13ms/step - loss: 0.3738 - mse: 27.7522 - mae: 4.4294 - accuracy: 0.8595 - root_mean_squared_error: 5.2680 - val_loss: 0.3785 - val_mse: 27.3972 - val_mae: 4.3824 - val_accuracy: 0.8568 - val_root_mean_squared_error: 5.2342\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.3696 - mse: 27.7523 - mae: 4.4294 - accuracy: 0.8606 - root_mean_squared_error: 5.2680 - val_loss: 0.3978 - val_mse: 27.3966 - val_mae: 4.3824 - val_accuracy: 0.8533 - val_root_mean_squared_error: 5.2342\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 20s 13ms/step - loss: 0.3669 - mse: 27.7526 - mae: 4.4294 - accuracy: 0.8631 - root_mean_squared_error: 5.2681 - val_loss: 0.3859 - val_mse: 27.3973 - val_mae: 4.3824 - val_accuracy: 0.8574 - val_root_mean_squared_error: 5.2342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 10:58:36.261277: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 9ms/step - loss: 0.4062 - mse: 27.6822 - mae: 4.4200 - accuracy: 0.8533 - root_mean_squared_error: 5.2614\n",
      "IM SAVING\n",
      "dict_keys(['loss', 'mse', 'mae', 'accuracy', 'root_mean_squared_error', 'val_loss', 'val_mse', 'val_mae', 'val_accuracy', 'val_root_mean_squared_error'])\n",
      "  6/313 [..............................] - ETA: 3s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 10:58:41.731825: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4062 - mse: 27.6822 - mae: 4.4200 - accuracy: 0.8533 - root_mean_squared_error: 5.2614\n",
      "Test Accuracy: [0.4062318205833435, 27.682172775268555, 4.419997215270996, 0.8532999753952026, 5.261385917663574]\n",
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mk/t6y50d7s2ds93t8l2lw18p_00000gn/T/ipykernel_15121/653596370.py:255: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
      "  plt.subplot(5, 5, i + 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"CNN\"\n",
    "number_of_epochs = 20\n",
    "\n",
    "AL = AutomaticLearning(train_images, train_labels, test_images, test_labels, model_name + \" to \" + str(number_of_epochs) + \" epochs\", model_name)\n",
    "AL.buildData()\n",
    "AL.buildModel()\n",
    "AL.train(number_of_epochs)\n",
    "AL.plot(model_name, save = True, show = False)\n",
    "result = AL.gather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MobileNet\"\n",
    "number_of_epochs = 20\n",
    "\n",
    "AL = AutomaticLearning(train_images, train_labels, test_images, test_labels, model_name + \" to \" + str(number_of_epochs) + \" epochs\", model_name)\n",
    "AL.buildData()\n",
    "AL.buildModel()\n",
    "AL.train(number_of_epochs)\n",
    "AL.plot(model_name, save = True, show = False)\n",
    "result = AL.gather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablo/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2023-06-06 10:28:54.803444: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - ETA: 0s - loss: 1.7891 - mse: 27.6891 - mae: 4.4294 - accuracy: 0.2411 - root_mean_squared_error: 5.2620"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 10:30:08.515207: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 94s 58ms/step - loss: 1.7891 - mse: 27.6891 - mae: 4.4294 - accuracy: 0.2411 - root_mean_squared_error: 5.2620 - val_loss: 1.6859 - val_mse: 27.3366 - val_mae: 4.3824 - val_accuracy: 0.2573 - val_root_mean_squared_error: 5.2284\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 77s 52ms/step - loss: 1.6382 - mse: 27.6930 - mae: 4.4294 - accuracy: 0.2808 - root_mean_squared_error: 5.2624 - val_loss: 1.5747 - val_mse: 27.3370 - val_mae: 4.3824 - val_accuracy: 0.3268 - val_root_mean_squared_error: 5.2285\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 86s 57ms/step - loss: 1.6019 - mse: 27.6941 - mae: 4.4294 - accuracy: 0.3008 - root_mean_squared_error: 5.2625 - val_loss: 1.5506 - val_mse: 27.3385 - val_mae: 4.3824 - val_accuracy: 0.3210 - val_root_mean_squared_error: 5.2286\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 86s 57ms/step - loss: 1.5665 - mse: 27.6950 - mae: 4.4294 - accuracy: 0.3212 - root_mean_squared_error: 5.2626 - val_loss: 1.5004 - val_mse: 27.3388 - val_mae: 4.3824 - val_accuracy: 0.3537 - val_root_mean_squared_error: 5.2287\n",
      "Epoch 5/20\n",
      "1235/1500 [=======================>......] - ETA: 13s - loss: 1.5282 - mse: 27.7785 - mae: 4.4393 - accuracy: 0.3433 - root_mean_squared_error: 5.2705"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m AL\u001b[39m.\u001b[39mbuildData()\n\u001b[1;32m      6\u001b[0m AL\u001b[39m.\u001b[39mbuildModel()\n\u001b[0;32m----> 7\u001b[0m AL\u001b[39m.\u001b[39;49mtrain(number_of_epochs)\n\u001b[1;32m      8\u001b[0m AL\u001b[39m.\u001b[39mplot(model_name, save \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, show \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m result \u001b[39m=\u001b[39m AL\u001b[39m.\u001b[39mgather_data()\n",
      "Cell \u001b[0;32mIn[37], line 374\u001b[0m, in \u001b[0;36mAutomaticLearning.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), optimizer \u001b[39m=\u001b[39m opt, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mRootMeanSquaredError()])      \n\u001b[1;32m    372\u001b[0m early_stop \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m250\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, shuffle \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,callbacks\u001b[39m=\u001b[39;49m[early_stop], verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    375\u001b[0m K\u001b[39m.\u001b[39mclear_session()\n\u001b[1;32m    376\u001b[0m \u001b[39m#['loss', 'mse', 'mae', 'root_mean_squared_error']\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = \"DenseNet\"\n",
    "number_of_epochs = 20\n",
    "\n",
    "AL = AutomaticLearning(train_images, train_labels, test_images, test_labels, model_name + \" to \" + str(number_of_epochs) + \" epochs\", model_name)\n",
    "AL.buildData()\n",
    "AL.buildModel()\n",
    "AL.train(number_of_epochs)\n",
    "AL.plot(model_name, save = True, show = False)\n",
    "result = AL.gather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ResNet\"\n",
    "number_of_epochs = 20\n",
    "\n",
    "AL = AutomaticLearning(train_images, train_labels, test_images, test_labels, model_name + \" to \" + str(number_of_epochs) + \" epochs\", model_name)\n",
    "AL.buildData()\n",
    "AL.buildModel()\n",
    "AL.train(number_of_epochs)\n",
    "AL.plot(model_name, save = True, show = False)\n",
    "result = AL.gather_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CNN\"\n",
    "number_of_epochs = 20\n",
    "\n",
    "AL = AutomaticLearning(train_images, train_labels, test_images, test_labels, model_name + \" to \" + str(number_of_epochs) + \" epochs\", model_name)\n",
    "AL.buildData()\n",
    "AL.buildModel()\n",
    "AL.train(number_of_epochs)\n",
    "AL.plot(model_name, save = True, show = False)\n",
    "result = AL.gather_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer = opt, metrics=['mse', 'mae','accuracy', tf.keras.metrics.RootMeanSquaredError()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1875 [..............................] - ETA: 8:20 - loss: 67.1922 - mse: 42.0496 - mae: 5.9375 - accuracy: 0.8125 - root_mean_squared_error: 6.4846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 09:30:22.300548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 739/1875 [==========>...................] - ETA: 11s - loss: 1.4198 - mse: 27.7255 - mae: 4.4232 - accuracy: 0.7212 - root_mean_squared_error: 5.2655"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_images, train_labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(test_images, test_labels))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/engine/training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1414\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1416\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/utils/tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    605\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 607\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/utils/tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    599\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 601\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    602\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.3562 - accuracy: 0.8904 - 2s/epoch - 5ms/step\n",
      "\n",
      "Test accuracy: 0.8903999924659729\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
